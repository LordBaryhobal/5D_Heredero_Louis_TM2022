\chapter{Introduction}
\label{chap:intro}
%Telecommunication has certainly been one of the most important development in the last century. From pigeons to Earth-Mars transmissions, a lot has happened. Nowadays, our society is all about information. Whether it is one's credit card number, the price of a dress or taxes, everything revolves around numbers and digital data.
%While the first computers and calculators used analog systems and could store any arbitrary type of data, our current devices are digital and only contain binary information. Inventors and developers were hence confronted to the challenge of encoding certain types of data in binary.

%We developed character encodings such as ASCII, UTF-8 or CP-1252, formats to store pictures, formats to store sounds, formats to store videos, etc. Many of these encodings have been standardized to facilitate communication between devices and are free to be used by anyone.

Computers and microprocessors are certainly the defining innovations of the end of the XX\textsuperscript{th} and beginning of the XXI\textsuperscript{st} centuries.
Invented to perform tasks faster and more reliably than humans, they truly have surpassed our mental capacities in many areas.
Although they overcome a great number of our shortcomings, especially in terms of speed, they are not infallible.
While many computer related bugs can be tracked down to a human error, some are inherent to the physical infrastructure of our technologies.
One major material limitation is the network connecting computers to each other.
For example, WiFi and mobile data use radio transmissions which are not perfectly reliable. Similarly, space communication implies a lot of interferences due to the atmosphere, space debris and all sorts of radiations.
Invalid data may also come from external sensors, would that be because they are malfunctioning or simply not able to correctly interpret there inputs.

As such, engineers and programmers have to devise methods to check that the data received is unaltered and provide a way of recovering the original information, or at least guess it.
These methods are most useful in fields where data is, or was, manually input.
As the saying goes, to err is human, and machines help us correct these errors.
Of course, these concerns are not new. Indeed, Claude Shannon had already started taking an interest in information theory in 1948\cite{information_theory}.
This scientific field which studies the characteristics and behaviors of information led to many technological improvements and fundamental theories, especially in computer science.

Barcodes and QR-Codes are two instances of the consequences and use of information theory. Their main benefit is to allow reliable identification of objects by computers. Prior to these inventions, it was the task of humans to manually tell machines what an object was, for example in supermarkets or factories. Now, a simple camera can quickly recognize items, without the use of artificial intelligence, which requires substantially higher computing capacity. Additionally, their simple designs make them very easy and efficient to implement, even on limited hardware.
